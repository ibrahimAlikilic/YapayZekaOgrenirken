{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ulke  boy  kilo  yas cinsiyet\n",
      "0    tr  130    30   10        e\n",
      "1    tr  125    36   11        e\n",
      "2    tr  135    34   10        k\n",
      "3    tr  133    30    9        k\n",
      "4    tr  129    38   12        e\n",
      "5    tr  180    90   30        e\n",
      "6    tr  190    80   25        e\n",
      "7    tr  175    90   35        e\n",
      "8    tr  177    60   22        k\n",
      "9    us  185   105   33        e\n",
      "10   us  165    55   27        k\n",
      "11   us  155    50   44        k\n",
      "12   us  160    58   39        k\n",
      "13   us  162    59   41        k\n",
      "14   us  167    62   55        k\n",
      "15   fr  174    70   47        e\n",
      "16   fr  193    90   23        e\n",
      "17   fr  187    80   27        e\n",
      "18   fr  183    88   28        e\n",
      "19   fr  159    40   29        k\n",
      "20   fr  164    66   32        k\n",
      "21   fr  166    56   42        k\n"
     ]
    }
   ],
   "source": [
    "# verileri okuyalım\n",
    "veriler=pd.read_csv('input/veriler.csv')\n",
    "print(veriler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    boy  kilo\n",
      "0   130    30\n",
      "1   125    36\n",
      "2   135    34\n",
      "3   133    30\n",
      "4   129    38\n",
      "5   180    90\n",
      "6   190    80\n",
      "7   175    90\n",
      "8   177    60\n",
      "9   185   105\n",
      "10  165    55\n",
      "11  155    50\n",
      "12  160    58\n",
      "13  162    59\n",
      "14  167    62\n",
      "15  174    70\n",
      "16  193    90\n",
      "17  187    80\n",
      "18  183    88\n",
      "19  159    40\n",
      "20  164    66\n",
      "21  166    56\n"
     ]
    }
   ],
   "source": [
    "boy=veriler[['boy']]\n",
    "boyKilo=veriler[['boy','kilo']]\n",
    "print(boyKilo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksik Veriler\n",
    "* sci - kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.impute import SimpleImputer:\\n\\n    Bu satır, scikit-learn kütüphanesinin impute modülünden SimpleImputer sınıfını içe aktarır. Bu sınıf, eksik verileri belirli bir stratejiye göre doldurmak için kullanılır.\\n\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\'mean\\'):\\n\\n    SimpleImputer(missing_values=np.nan, strategy=\\'mean\\'): Bu, SimpleImputer sınıfından bir örnek oluşturur.\\n        missing_values=np.nan: Eksik değerlerin NaN (Not a Number) olduğunu belirtir. Yani, NaN olan hücreler eksik veri olarak kabul edilir.\\n        strategy=\\'mean\\': Eksik değerlerin doldurulma stratejisini belirtir. Burada, eksik değerler ilgili sütunun \" ortalama değeri \" ile doldurulacaktır.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "'''\n",
    "from sklearn.impute import SimpleImputer:\n",
    "\n",
    "    Bu satır, scikit-learn kütüphanesinin impute modülünden SimpleImputer sınıfını içe aktarır. Bu sınıf, eksik verileri belirli bir stratejiye göre doldurmak için kullanılır.\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean'):\n",
    "\n",
    "    SimpleImputer(missing_values=np.nan, strategy='mean'): Bu, SimpleImputer sınıfından bir örnek oluşturur.\n",
    "        missing_values=np.nan: Eksik değerlerin NaN (Not a Number) olduğunu belirtir. Yani, NaN olan hücreler eksik veri olarak kabul edilir.\n",
    "        strategy='mean': Eksik değerlerin doldurulma stratejisini belirtir. Burada, eksik değerler ilgili sütunun \" ortalama değeri \" ile doldurulacaktır.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  30  10]\n",
      " [125  36  11]\n",
      " [135  34  10]\n",
      " [133  30   9]\n",
      " [129  38  12]\n",
      " [180  90  30]\n",
      " [190  80  25]\n",
      " [175  90  35]\n",
      " [177  60  22]\n",
      " [185 105  33]\n",
      " [165  55  27]\n",
      " [155  50  44]\n",
      " [160  58  39]\n",
      " [162  59  41]\n",
      " [167  62  55]\n",
      " [174  70  47]\n",
      " [193  90  23]\n",
      " [187  80  27]\n",
      " [183  88  28]\n",
      " [159  40  29]\n",
      " [164  66  32]\n",
      " [166  56  42]]\n"
     ]
    }
   ],
   "source": [
    "# Eğer elimdeki veri setinde yas sütununda eksik olsaydı o kısmı ortalama değer ( mean ) ile doldurmuş olacaktım\n",
    "Yas=veriler.iloc[:,1:4].values\n",
    "imputer=imputer.fit(Yas[:,1:4])\n",
    "print(Yas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresyon oluşturabilmek için numeric değerlere ihtiyacım var bu sebepten cinsiyet ve üşke kolonlarındaki değerleri değiştireceğiz<br>\n",
    "## Encoding kullanacağız.<br>\n",
    "* encoder: Kategorik -> Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cinsiyet için :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']]\n"
     ]
    }
   ],
   "source": [
    "# cinsiyet yerine c şeklinde isimlendirdik\n",
    "c=veriler.iloc[:,-1:].values\n",
    "'''\n",
    "veriler.iloc[:,-1:]:\n",
    "\n",
    "    iloc[] yöntemi, Pandas DataFrame'deki satır ve sütunları konumlarına göre seçmeye yarar.\n",
    "    : ifadesi, tüm satırları seçtiğimizi belirtir.\n",
    "    -1: ifadesi, en son sütunu seçer. : kullanımıyla birlikte en sondan başlayarak (yalnızca bir sütun olduğu için) bu sütunu seçer.\n",
    "\n",
    "Bu adımda, veriler DataFrame'inin tüm satırlarının son sütunu seçiliyor.\n",
    "\n",
    ".values:\n",
    "\n",
    "    .values özelliği, Pandas DataFrame'i veya Serisini bir NumPy dizisine dönüştürür.\n",
    "\n",
    "Bu adımda, seçilen son sütunu bir NumPy dizisi haline getiriyoruz.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing # Bu modül, veri ön işleme (preprocessing) işlemleri için çeşitli araçlar sunar.\n",
    "le=preprocessing.LabelEncoder()\n",
    "# LabelEncoder sınıfından bir örnek oluşturuyoruz. LabelEncoder, kategorik verileri sayısal verilere dönüştürmek için kullanılır.\n",
    "# Örneğin, [\"kırmızı\", \"yeşil\", \"mavi\"] gibi kategorik değerleri [0, 1, 2] gibi sayısal değerlere dönüştürür.\n",
    "c[:,-1]=le.fit_transform(veriler.iloc[:,-1])\n",
    "'''\n",
    "c[:,-1] = le.fit_transform(veriler.iloc[:,-1]):\n",
    "\n",
    "    veriler.iloc[:,-1]: Bu, veriler DataFrame'inin son sütununu seçer. iloc yöntemi, DataFrame'in belirli bir dilimini seçmek için kullanılır.\n",
    "    le.fit_transform(...): fit_transform yöntemi, önce etiket kodlayıcısını kategorik verilerle eğitir (fit), ardından bu verileri sayısal değerlere dönüştürür (transform).\n",
    "    c[:,-1] = ...: c NumPy dizisinin son sütununa, dönüştürülmüş sayısal değerler atanır.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ohe=preprocessing.OneHotEncoder()\n",
    "c=ohe.fit_transform(c).toarray()\n",
    "'''\n",
    "Bu kod parçası, LabelEncoder ile sayısal değerlere dönüştürülmüş olan kategorik verileri, OneHotEncoder kullanarak tekil (one-hot) kodlamaya dönüştürüyor. Adım adım açıklayalım:\n",
    "ohe = preprocessing.OneHotEncoder():\n",
    "\n",
    "    OneHotEncoder sınıfından bir örnek oluşturuyoruz. OneHotEncoder, kategorik verileri ikili (binary) vektörlere dönüştürmek için kullanılır. \n",
    "    Örneğin, 0, 1 ve 2 gibi sayısal kategorileri şu şekilde vektörlere dönüştürür: [1,0,0], [0,1,0] ve [0,0,1].\n",
    "\n",
    "c = ohe.fit_transform(c).toarray():\n",
    "\n",
    "    fit_transform(c): OneHotEncoder'ı veri seti c ile eğitir (fit) ve ardından bu verileri one-hot kodlamalı vektörlere dönüştürür (transform).\n",
    "    toarray(): Bu, elde edilen sparse matrisini (seyrek matris) yoğun (dense) bir NumPy dizisine dönüştürür.\n",
    "    Bu, verilerin kolayca işlenebilmesi ve analiz edilebilmesi için gereklidir.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülke için :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ulke=veriler.iloc[:,0:1].values\n",
    "ulke[:,0]=le.fit_transform(veriler.iloc[:,0])\n",
    "ohe=preprocessing.OneHotEncoder()\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "print(ulke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cinsiyet\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        1.0\n",
      "5        1.0\n",
      "6        1.0\n",
      "7        1.0\n",
      "8        0.0\n",
      "9        1.0\n",
      "10       0.0\n",
      "11       0.0\n",
      "12       0.0\n",
      "13       0.0\n",
      "14       0.0\n",
      "15       1.0\n",
      "16       1.0\n",
      "17       1.0\n",
      "18       1.0\n",
      "19       0.0\n",
      "20       0.0\n",
      "21       0.0\n"
     ]
    }
   ],
   "source": [
    "# Numpy dizileri dataframe donusumu\n",
    "sonuc=pd.DataFrame(data=ulke,index=range(22),columns=['fr','tr','us'])\n",
    "sonuc2=pd.DataFrame(data=Yas,index=range(22),columns=['boy','kilo','yas'])\n",
    "cinsiyet=veriler.iloc[:,-1].values\n",
    "sonuc3=pd.DataFrame(data=c[:,:1],index=range(22),columns=['cinsiyet']) # hem 0 hem 1 kolonunu almamamız lazım o kısım çok önemli\n",
    "print(sonuc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Birleştirme İşlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us  boy  kilo  yas  cinsiyet\n",
      "0   0.0  1.0  0.0  130    30   10       1.0\n",
      "1   0.0  1.0  0.0  125    36   11       1.0\n",
      "2   0.0  1.0  0.0  135    34   10       0.0\n",
      "3   0.0  1.0  0.0  133    30    9       0.0\n",
      "4   0.0  1.0  0.0  129    38   12       1.0\n",
      "5   0.0  1.0  0.0  180    90   30       1.0\n",
      "6   0.0  1.0  0.0  190    80   25       1.0\n",
      "7   0.0  1.0  0.0  175    90   35       1.0\n",
      "8   0.0  1.0  0.0  177    60   22       0.0\n",
      "9   0.0  0.0  1.0  185   105   33       1.0\n",
      "10  0.0  0.0  1.0  165    55   27       0.0\n",
      "11  0.0  0.0  1.0  155    50   44       0.0\n",
      "12  0.0  0.0  1.0  160    58   39       0.0\n",
      "13  0.0  0.0  1.0  162    59   41       0.0\n",
      "14  0.0  0.0  1.0  167    62   55       0.0\n",
      "15  1.0  0.0  0.0  174    70   47       1.0\n",
      "16  1.0  0.0  0.0  193    90   23       1.0\n",
      "17  1.0  0.0  0.0  187    80   27       1.0\n",
      "18  1.0  0.0  0.0  183    88   28       1.0\n",
      "19  1.0  0.0  0.0  159    40   29       0.0\n",
      "20  1.0  0.0  0.0  164    66   32       0.0\n",
      "21  1.0  0.0  0.0  166    56   42       0.0\n"
     ]
    }
   ],
   "source": [
    "s=pd.concat([sonuc,sonuc2],axis=1)\n",
    "'''\n",
    "s = pd.concat([sonuc, sonuc2], axis=1):\n",
    "\n",
    "    pd.concat(): pandas kütüphanesindeki concat fonksiyonu, iki veya daha fazla DataFrame'i birleştirmek için kullanılır.\n",
    "    [sonuc, sonuc2]: Bu, birleştirilecek olan iki DataFrame'i içeren bir listedir.\n",
    "    axis=1: Bu parametre, birleştirmenin sütun bazında yapılacağını belirtir. Yani, sonuc ve sonuc2 DataFrame'leri yatay olarak yan yana eklenir.\n",
    "    s: Bu, birleştirilmiş yeni DataFrame'i tutan değişkendir.\n",
    "'''\n",
    "s2=pd.concat([s,sonuc3],axis=1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin Eğitilmesi ve Test İçin Bölünmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :\n",
      "     fr   tr   us  boy  kilo  yas\n",
      "8   0.0  1.0  0.0  177    60   22\n",
      "6   0.0  1.0  0.0  190    80   25\n",
      "16  1.0  0.0  0.0  193    90   23\n",
      "4   0.0  1.0  0.0  129    38   12\n",
      "2   0.0  1.0  0.0  135    34   10\n",
      "5   0.0  1.0  0.0  180    90   30\n",
      "17  1.0  0.0  0.0  187    80   27\n",
      "9   0.0  0.0  1.0  185   105   33\n",
      "7   0.0  1.0  0.0  175    90   35\n",
      "18  1.0  0.0  0.0  183    88   28\n",
      "3   0.0  1.0  0.0  133    30    9\n",
      "0   0.0  1.0  0.0  130    30   10\n",
      "15  1.0  0.0  0.0  174    70   47\n",
      "12  0.0  0.0  1.0  160    58   39\n",
      "x_test :\n",
      "     fr   tr   us  boy  kilo  yas\n",
      "20  1.0  0.0  0.0  164    66   32\n",
      "10  0.0  0.0  1.0  165    55   27\n",
      "14  0.0  0.0  1.0  167    62   55\n",
      "13  0.0  0.0  1.0  162    59   41\n",
      "1   0.0  1.0  0.0  125    36   11\n",
      "21  1.0  0.0  0.0  166    56   42\n",
      "11  0.0  0.0  1.0  155    50   44\n",
      "19  1.0  0.0  0.0  159    40   29\n",
      "y_train :\n",
      "    cinsiyet\n",
      "8        0.0\n",
      "6        1.0\n",
      "16       1.0\n",
      "4        1.0\n",
      "2        0.0\n",
      "5        1.0\n",
      "17       1.0\n",
      "9        1.0\n",
      "7        1.0\n",
      "18       1.0\n",
      "3        0.0\n",
      "0        1.0\n",
      "15       1.0\n",
      "12       0.0\n",
      "y_test :\n",
      "    cinsiyet\n",
      "20       0.0\n",
      "10       0.0\n",
      "14       0.0\n",
      "13       0.0\n",
      "1        1.0\n",
      "21       0.0\n",
      "11       0.0\n",
      "19       0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Bu satır, scikit-learn kütüphanesinden train_test_split fonksiyonunu içe aktarır. Bu fonksiyon, veri setlerini eğitim ve test setlerine ayırmak için kullanılır.\n",
    "x_train,x_test , y_train,y_test=train_test_split(s,sonuc3,test_size=0.33,random_state=0)\n",
    "'''\n",
    "train_test_split(s, sonuc3, test_size=0.33, random_state=0): Bu, s ve sonuc3 veri setlerini eğitim ve test setlerine ayırır.\n",
    "\n",
    "    s: Özellikleri (features) temsil eden DataFrame.\n",
    "    sonuc3: Hedef değişkeni (labels) temsil eden DataFrame.\n",
    "    test_size=0.33: Verilerin %33'ünün test setine, geri kalan %67'sinin eğitim setine ayrılacağını belirtir.\n",
    "    random_state=0: Rastgelelik kontrolü için sabit bir rastgelelik durumunu belirler. Bu, aynı verilerle aynı sonuçları elde etmek için kullanılır.\n",
    "'''\n",
    "print(\"x_train :\")\n",
    "print(x_train)\n",
    "print(\"x_test :\")\n",
    "print(x_test)\n",
    "print(\"y_train :\")\n",
    "print(y_train)\n",
    "print(\"y_test :\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin Ölçeklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntransform(x_test): StandardScaler'ı önceden fit edilen (eğitilen) parametrelerle x_test veri setine uygular. Bu, test verilerini aynı ölçekte standartlaştırır.\\nBu adımda sadece transform kullanılır, çünkü fit_transform kullanmak test verisinin eğitim verisine göre farklı bir ölçeklendirilmesine yol açabilir.\\nEğitim ve test verilerinin aynı ölçekte olması gerekmektedir.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Bu kod parçası, StandardScaler kullanarak eğitim ve test verilerini ölçeklendirir. \n",
    "StandardScaler, verileri standartlaştırarak her özelliğin ortalamasını 0 ve standart sapmasını 1 yapar. \n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Bu satır, scikit-learn kütüphanesinden StandardScaler sınıfını içe aktarır. Bu sınıf, verileri standartlaştırmak için kullanılır.\n",
    "sc=StandardScaler()\n",
    "# StandardScaler sınıfından bir örnek oluşturur. Bu örnek, fit edilip dönüştürülecek veriler için kullanılacaktır.\n",
    "X_train=sc.fit_transform(x_train)\n",
    "'''\n",
    "fit_transform(x_train): StandardScaler'ı x_train veri seti üzerinde fit eder ve ardından bu veri setini dönüştürür. \n",
    "Bu, x_train veri setinin her bir özelliğini standartlaştırır (ortalaması 0, standart sapması 1 olacak şekilde).\n",
    "'''\n",
    "X_test=sc.fit_transform(x_test)\n",
    "'''\n",
    "transform(x_test): StandardScaler'ı önceden fit edilen (eğitilen) parametrelerle x_test veri setine uygular. Bu, test verilerini aynı ölçekte standartlaştırır.\n",
    "Bu adımda sadece transform kullanılır, çünkü fit_transform kullanmak test verisinin eğitim verisine göre farklı bir ölçeklendirilmesine yol açabilir.\n",
    "Eğitim ve test verilerinin aynı ölçekte olması gerekmektedir.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98720204]\n",
      " [-0.12036863]\n",
      " [ 0.05009703]\n",
      " [ 0.07137418]\n",
      " [ 0.72473935]\n",
      " [ 0.64615044]\n",
      " [-0.03567453]\n",
      " [ 0.32612171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # Bu sınıf, doğrusal regresyon modeli oluşturmak için kullanılır.\n",
    "regressor=LinearRegression() # LinearRegression sınıfından bir örnek oluşturur. Bu örnek, regresyon modelini temsil eder ve modelin özelliklerini ve metodlarını içerir.\n",
    "regressor.fit(x_train,y_train)\n",
    "'''\n",
    "fit(x_train, y_train): Bu metot, doğrusal regresyon modelini eğitim verileri (x_train) ve hedef değişkenler (y_train) ile eğitir.\n",
    "x_train: Eğitim verisi olarak kullanılan özellikler (features). Bu veriler, modelin bağımsız değişkenleridir.\n",
    "y_train: Eğitim verisi olarak kullanılan hedef değişkenler (labels). Bu veriler, modelin bağımlı değişkenleridir.\n",
    "fit metodu, verilen eğitim verilerini kullanarak modelin parametrelerini (ağırlıklar ve sapma) öğrenir.\n",
    "'''\n",
    "\n",
    "# şimdi tahmin işlemini yapacağız\n",
    "y_pred=regressor.predict(x_test)\n",
    "'''\n",
    "predict(x_test): Bu metot, eğitilmiş model kullanılarak x_test veri seti için tahminler yapar.\n",
    "x_test: Test verisi olarak kullanılan özellikler (features). Bu veriler, modelin bağımsız değişkenleridir.\n",
    "y_pred: Bu değişken, modelin x_test verilerine karşılık olarak yaptığı tahminleri tutar. Tahmin edilen hedef değişkenler (labels) burada saklanır.\n",
    "'''\n",
    "print(y_pred) # - gelmiş olan sonuçları yanlış tahminde bulunmuş olarak değerlendirebiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cinsiyet\n",
      "20       0.0\n",
      "10       0.0\n",
      "14       0.0\n",
      "13       0.0\n",
      "1        1.0\n",
      "21       0.0\n",
      "11       0.0\n",
      "19       0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çıktıları görselleştirerek kaydetme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def Kayit(variables):\n",
    "    # \"output\" klasörünün yolu\n",
    "    output_dir = 'output'\n",
    "    \n",
    "    # Klasör yoksa oluştur\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Her bir değişkeni görselleştirip kaydetme işlemi\n",
    "    for var_name, var_data in variables.items():\n",
    "        # Değişkeni DataFrame'e dönüştürme (eğer değilse)\n",
    "        if not isinstance(var_data, pd.DataFrame):\n",
    "            var_data = pd.DataFrame(var_data)\n",
    "    \n",
    "        # DataFrame'i bir ısı haritası olarak görselleştirme\n",
    "        plt.figure(figsize=(5, len(var_data) // 2))\n",
    "        sns.heatmap(var_data, annot=True, cmap=\"coolwarm\", cbar=False, annot_kws={\"size\": 10})\n",
    "    \n",
    "        # Görseli \"output\" klasörüne değişken adıyla bir dosyaya kaydetme\n",
    "        file_path = os.path.join(output_dir, f'{var_name}.png')\n",
    "        plt.savefig(file_path, bbox_inches='tight')\n",
    "        plt.close() \n",
    "    \n",
    "    print(\"Tüm değişkenler görselleştirilip dosyalara kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm değişkenler görselleştirilip dosyalara kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Görselleştirmek ve kaydetme işlemi\n",
    "variables = {\n",
    "    \"s\": s,\n",
    "    \"s2\": s2,\n",
    "    \"x_train\": x_train,\n",
    "    \"x_test\": x_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "    \"X_train\": X_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_pred\": y_pred\n",
    "}\n",
    "Kayit(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kütüphanelerin İçe Aktarılması:,\n",
    "* pandas (pd): Veri manipülasyonu ve analizi için kullanılır.\n",
    "* matplotlib.pyplot (plt): Veri görselleştirme için kullanılır.\n",
    "* seaborn (sns): Matplotlib üzerine kurulu bir kütüphane olup, istatistiksel grafikler oluşturmak için kullanılır.\n",
    "2. Her Bir Değişkeni Görselleştirme ve Kaydetme:\n",
    "* for döngüsü ile sözlükteki her bir değişkeni (anahtar-değer çiftini) işleme alıyoruz.\n",
    "* var_name değişken adını, var_data ise değişkenin kendisini temsil eder.\n",
    "* isinstance(var_data, pd.DataFrame): Eğer var_data bir DataFrame değilse, pd.DataFrame(var_data) ile onu bir DataFrame'e dönüştürüyoruz. Bu, tüm verilerin aynı formatta olmasını sağlar.\n",
    "3. Isı Haritası Oluşturma:\n",
    "* plt.figure(figsize=(5, len(var_data) // 2)): Görselin boyutunu ayarlıyoruz. Genişlik 5, yükseklik ise veri uzunluğunun yarısı olacak şekilde ayarlanır. Bu, her veri setinin boyutuna göre uygun bir görsel boyutu sağlar.\n",
    "* sns.heatmap(var_data, annot=True, cmap=\"coolwarm\", cbar=False, annot_kws={\"size\": 10}): Seaborn kütüphanesi kullanılarak bir ısı haritası oluşturuyoruz.\n",
    "    * var_data: Görselleştirilecek veri.\n",
    "    * annot=True: Hücrelerin içine veri değerlerini yazdırır.\n",
    "    * cmap=\"coolwarm\": Isı haritası için kullanılan renk paleti. \"coolwarm\" mavi ve kırmızı tonlarını içerir.\n",
    "    * cbar=False: Renk çubuğunu gizler.\n",
    "    * annot_kws={\"size\": 10}: Hücrelerdeki yazı boyutunu ayarlar.\n",
    "4. Görseli Kaydetme:\n",
    "* bbox_inches='tight': Görselin etrafındaki boşlukları minimuma indirir ve sıkıştırılmış bir şekilde kaydedilmesini sağlar.\n",
    "* plt.close(): Mevcut çizimi kapatır. Bu, bir sonraki çizim için temiz bir başlangıç yapmamızı sağlar ve bellekte gereksiz yer kaplamayı önler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boy Tahmini yapacağız\n",
    "\n",
    "* Boy kolonunun sağ ve solundakileri 1 dataFrame haline getireceğiz ve boy da tek başına bir y kolonu olarak çıkacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130]\n",
      " [125]\n",
      " [135]\n",
      " [133]\n",
      " [129]\n",
      " [180]\n",
      " [190]\n",
      " [175]\n",
      " [177]\n",
      " [185]\n",
      " [165]\n",
      " [155]\n",
      " [160]\n",
      " [162]\n",
      " [167]\n",
      " [174]\n",
      " [193]\n",
      " [187]\n",
      " [183]\n",
      " [159]\n",
      " [164]\n",
      " [166]]\n"
     ]
    }
   ],
   "source": [
    "boy=s2.iloc[:,3:4].values # bağımlı değişkenleri içeren kolonum\n",
    "print(boy)\n",
    "sol=s2.iloc[:,:3]\n",
    "sag=s2.iloc[:,4:]\n",
    "veri=pd.concat([sol,sag],axis=1) # bağımsız değişkenleri içeren veri kümem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_boy,x_test_boy , y_train_boy,y_test_boy=train_test_split(veri,boy,test_size=0.33,random_state=0)\n",
    "r2=LinearRegression()\n",
    "r2.fit(x_train_boy,y_train_boy)\n",
    "y_pred_boy=r2.predict(x_test_boy)\n",
    "# x_test_boy dan y_test_boy verilerini tahmin edecek ve tahminler y_pred_boy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm değişkenler görselleştirilip dosyalara kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Görselleştirmek ve kaydetme işlemi\n",
    "variables = {\n",
    "    \"boy\": boy,\n",
    "    \"sol\": sol,\n",
    "    \"sag\": sag,\n",
    "    \"veri\": veri,\n",
    "    \"x_train_boy\": x_train_boy,\n",
    "    \"x_test_boy\": x_test_boy,\n",
    "    \"y_train_boy\": y_train_boy,\n",
    "    \"y_test_boy\": y_test_boy,\n",
    "    \"y_pred_boy\": y_pred_boy\n",
    "}\n",
    "Kayit(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Elimination\n",
    "* Amacımız hangi değişken sistemin yapısını daha fazla bozuyorsa onu sistemden çıkarmak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   1.   0.  30.  10.   1.]\n",
      " [  1.   0.   1.   0.  36.  11.   1.]\n",
      " [  1.   0.   1.   0.  34.  10.   0.]\n",
      " [  1.   0.   1.   0.  30.   9.   0.]\n",
      " [  1.   0.   1.   0.  38.  12.   1.]\n",
      " [  1.   0.   1.   0.  90.  30.   1.]\n",
      " [  1.   0.   1.   0.  80.  25.   1.]\n",
      " [  1.   0.   1.   0.  90.  35.   1.]\n",
      " [  1.   0.   1.   0.  60.  22.   0.]\n",
      " [  1.   0.   0.   1. 105.  33.   1.]\n",
      " [  1.   0.   0.   1.  55.  27.   0.]\n",
      " [  1.   0.   0.   1.  50.  44.   0.]\n",
      " [  1.   0.   0.   1.  58.  39.   0.]\n",
      " [  1.   0.   0.   1.  59.  41.   0.]\n",
      " [  1.   0.   0.   1.  62.  55.   0.]\n",
      " [  1.   1.   0.   0.  70.  47.   1.]\n",
      " [  1.   1.   0.   0.  90.  23.   1.]\n",
      " [  1.   1.   0.   0.  80.  27.   1.]\n",
      " [  1.   1.   0.   0.  88.  28.   1.]\n",
      " [  1.   1.   0.   0.  40.  29.   0.]\n",
      " [  1.   1.   0.   0.  66.  32.   0.]\n",
      " [  1.   1.   0.   0.  56.  42.   0.]]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X=np.append(arr=np.ones((22,1)).astype(int),values=veri,axis=1)\n",
    "# 22 satır 1 sütundan oluşan dizi oluştur , values=veri demek veri dizisine ekle et demek, axis=1 demek sütun olarak ekle demek\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 19 Jul 2024   Prob (F-statistic):           5.41e-07\n",
      "Time:                        14:06:10   Log-Likelihood:                -73.950\n",
      "No. Observations:                  22   AIC:                             159.9\n",
      "Df Residuals:                      16   BIC:                             166.4\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           114.0688      8.145     14.005      0.000      96.802     131.335\n",
      "x2           108.3030      5.736     18.880      0.000      96.143     120.463\n",
      "x3           104.4714      9.195     11.361      0.000      84.978     123.964\n",
      "x4             0.9211      0.119      7.737      0.000       0.669       1.174\n",
      "x5             0.0814      0.221      0.369      0.717      -0.386       0.549\n",
      "x6           -10.5980      5.052     -2.098      0.052     -21.308       0.112\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                         524.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_l=veri.iloc[:,[0,1,2,3,4,5]].values\n",
    "X_l=np.array(X_l,dtype=float)\n",
    "model=sm.OLS(boy,X_l).fit() # bu sayede hangi değişkenin ne kadar etki ettiğini öğreniyoruz\n",
    "'''\n",
    "sm.OLS(boy, X_l):\n",
    "\n",
    "    sm.OLS: statsmodels kütüphanesinde OLS modelini tanımlayan sınıftır.\n",
    "    boy: Hedef değişken (bağımlı değişken). Modelin tahmin etmeye çalıştığı değeri temsil eder.\n",
    "    X_l: Özellikler matrisi (bağımsız değişkenler). Modelin hedef değişkeni tahmin etmek için kullandığı verileri temsil eder.\n",
    "    Bu kısım, bir OLS model nesnesi oluşturur, ancak model henüz eğitilmemiştir.\n",
    "\n",
    ".fit():\n",
    "\n",
    "    fit metodu, modeli verilen veriler üzerinde eğitir.\n",
    "    Bu işlem, model parametrelerini (örneğin, regresyon katsayılarını) en iyi şekilde tahmin etmeye çalışır.\n",
    "    .fit() metodunu çağırdıktan sonra, model değişkeni eğitilmiş model nesnesini içerir.\n",
    "'''\n",
    "print(model.summary()) # burada \" P>|t|\" değerine bakıyoruz ne kadar düşükse bizim için o kadar iyidir. Diğerlerinden önümüzdeki derslerde bahsedecekmiş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.884\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     32.47\n",
      "Date:                Fri, 19 Jul 2024   Prob (F-statistic):           9.32e-08\n",
      "Time:                        14:09:32   Log-Likelihood:                -74.043\n",
      "No. Observations:                  22   AIC:                             158.1\n",
      "Df Residuals:                      17   BIC:                             163.5\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           115.6583      6.734     17.175      0.000     101.451     129.866\n",
      "x2           109.0786      5.200     20.978      0.000      98.108     120.049\n",
      "x3           106.5445      7.090     15.026      0.000      91.585     121.504\n",
      "x4             0.9405      0.104      9.029      0.000       0.721       1.160\n",
      "x5           -11.1093      4.733     -2.347      0.031     -21.096      -1.123\n",
      "==============================================================================\n",
      "Omnibus:                        0.871   Durbin-Watson:                   2.719\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.459\n",
      "Skew:                           0.351   Prob(JB):                        0.795\n",
      "Kurtosis:                       2.910   Cond. No.                         397.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# en yüksek değeri vermiş olan 4. elemanı eliyorum\n",
    "X_l=veri.iloc[:,[0,1,2,3,5]].values\n",
    "X_l=np.array(X_l,dtype=float)\n",
    "model=sm.OLS(boy,X_l).fit()\n",
    "print(model.summary()) # x5 kabul edilebilir ama istersen onu da çıkartabliirsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
