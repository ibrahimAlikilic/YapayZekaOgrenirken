{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ulke  boy  kilo  yas cinsiyet\n",
      "0    tr  130    30   10        e\n",
      "1    tr  125    36   11        e\n",
      "2    tr  135    34   10        k\n",
      "3    tr  133    30    9        k\n",
      "4    tr  129    38   12        e\n",
      "5    tr  180    90   30        e\n",
      "6    tr  190    80   25        e\n",
      "7    tr  175    90   35        e\n",
      "8    tr  177    60   22        k\n",
      "9    us  185   105   33        e\n",
      "10   us  165    55   27        k\n",
      "11   us  155    50   44        k\n",
      "12   us  160    58   39        k\n",
      "13   us  162    59   41        k\n",
      "14   us  167    62   55        k\n",
      "15   fr  174    70   47        e\n",
      "16   fr  193    90   23        e\n",
      "17   fr  187    80   27        e\n",
      "18   fr  183    88   28        e\n",
      "19   fr  159    40   29        k\n",
      "20   fr  164    66   32        k\n",
      "21   fr  166    56   42        k\n"
     ]
    }
   ],
   "source": [
    "# verileri okuyalım\n",
    "veriler=pd.read_csv('input/veriler.csv')\n",
    "print(veriler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    boy  kilo\n",
      "0   130    30\n",
      "1   125    36\n",
      "2   135    34\n",
      "3   133    30\n",
      "4   129    38\n",
      "5   180    90\n",
      "6   190    80\n",
      "7   175    90\n",
      "8   177    60\n",
      "9   185   105\n",
      "10  165    55\n",
      "11  155    50\n",
      "12  160    58\n",
      "13  162    59\n",
      "14  167    62\n",
      "15  174    70\n",
      "16  193    90\n",
      "17  187    80\n",
      "18  183    88\n",
      "19  159    40\n",
      "20  164    66\n",
      "21  166    56\n"
     ]
    }
   ],
   "source": [
    "boy=veriler[['boy']]\n",
    "boyKilo=veriler[['boy','kilo']]\n",
    "print(boyKilo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksik Veriler\n",
    "* sci - kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.impute import SimpleImputer:\\n\\n    Bu satır, scikit-learn kütüphanesinin impute modülünden SimpleImputer sınıfını içe aktarır. Bu sınıf, eksik verileri belirli bir stratejiye göre doldurmak için kullanılır.\\n\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\'mean\\'):\\n\\n    SimpleImputer(missing_values=np.nan, strategy=\\'mean\\'): Bu, SimpleImputer sınıfından bir örnek oluşturur.\\n        missing_values=np.nan: Eksik değerlerin NaN (Not a Number) olduğunu belirtir. Yani, NaN olan hücreler eksik veri olarak kabul edilir.\\n        strategy=\\'mean\\': Eksik değerlerin doldurulma stratejisini belirtir. Burada, eksik değerler ilgili sütunun \" ortalama değeri \" ile doldurulacaktır.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "'''\n",
    "from sklearn.impute import SimpleImputer:\n",
    "\n",
    "    Bu satır, scikit-learn kütüphanesinin impute modülünden SimpleImputer sınıfını içe aktarır. Bu sınıf, eksik verileri belirli bir stratejiye göre doldurmak için kullanılır.\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean'):\n",
    "\n",
    "    SimpleImputer(missing_values=np.nan, strategy='mean'): Bu, SimpleImputer sınıfından bir örnek oluşturur.\n",
    "        missing_values=np.nan: Eksik değerlerin NaN (Not a Number) olduğunu belirtir. Yani, NaN olan hücreler eksik veri olarak kabul edilir.\n",
    "        strategy='mean': Eksik değerlerin doldurulma stratejisini belirtir. Burada, eksik değerler ilgili sütunun \" ortalama değeri \" ile doldurulacaktır.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  30  10]\n",
      " [125  36  11]\n",
      " [135  34  10]\n",
      " [133  30   9]\n",
      " [129  38  12]\n",
      " [180  90  30]\n",
      " [190  80  25]\n",
      " [175  90  35]\n",
      " [177  60  22]\n",
      " [185 105  33]\n",
      " [165  55  27]\n",
      " [155  50  44]\n",
      " [160  58  39]\n",
      " [162  59  41]\n",
      " [167  62  55]\n",
      " [174  70  47]\n",
      " [193  90  23]\n",
      " [187  80  27]\n",
      " [183  88  28]\n",
      " [159  40  29]\n",
      " [164  66  32]\n",
      " [166  56  42]]\n"
     ]
    }
   ],
   "source": [
    "# Eğer elimdeki veri setinde yas sütununda eksik olsaydı o kısmı ortalama değer ( mean ) ile doldurmuş olacaktım\n",
    "Yas=veriler.iloc[:,1:4].values\n",
    "imputer=imputer.fit(Yas[:,1:4])\n",
    "print(Yas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresyon oluşturabilmek için numeric değerlere ihtiyacım var bu sebepten cinsiyet ve üşke kolonlarındaki değerleri değiştireceğiz<br>\n",
    "## Encoding kullanacağız.<br>\n",
    "* encoder: Kategorik -> Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cinsiyet için :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']]\n"
     ]
    }
   ],
   "source": [
    "# cinsiyet yerine c şeklinde isimlendirdik\n",
    "c=veriler.iloc[:,-1:].values\n",
    "'''\n",
    "veriler.iloc[:,-1:]:\n",
    "\n",
    "    iloc[] yöntemi, Pandas DataFrame'deki satır ve sütunları konumlarına göre seçmeye yarar.\n",
    "    : ifadesi, tüm satırları seçtiğimizi belirtir.\n",
    "    -1: ifadesi, en son sütunu seçer. : kullanımıyla birlikte en sondan başlayarak (yalnızca bir sütun olduğu için) bu sütunu seçer.\n",
    "\n",
    "Bu adımda, veriler DataFrame'inin tüm satırlarının son sütunu seçiliyor.\n",
    "\n",
    ".values:\n",
    "\n",
    "    .values özelliği, Pandas DataFrame'i veya Serisini bir NumPy dizisine dönüştürür.\n",
    "\n",
    "Bu adımda, seçilen son sütunu bir NumPy dizisi haline getiriyoruz.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing # Bu modül, veri ön işleme (preprocessing) işlemleri için çeşitli araçlar sunar.\n",
    "le=preprocessing.LabelEncoder()\n",
    "# LabelEncoder sınıfından bir örnek oluşturuyoruz. LabelEncoder, kategorik verileri sayısal verilere dönüştürmek için kullanılır.\n",
    "# Örneğin, [\"kırmızı\", \"yeşil\", \"mavi\"] gibi kategorik değerleri [0, 1, 2] gibi sayısal değerlere dönüştürür.\n",
    "c[:,-1]=le.fit_transform(veriler.iloc[:,-1])\n",
    "'''\n",
    "c[:,-1] = le.fit_transform(veriler.iloc[:,-1]):\n",
    "\n",
    "    veriler.iloc[:,-1]: Bu, veriler DataFrame'inin son sütununu seçer. iloc yöntemi, DataFrame'in belirli bir dilimini seçmek için kullanılır.\n",
    "    le.fit_transform(...): fit_transform yöntemi, önce etiket kodlayıcısını kategorik verilerle eğitir (fit), ardından bu verileri sayısal değerlere dönüştürür (transform).\n",
    "    c[:,-1] = ...: c NumPy dizisinin son sütununa, dönüştürülmüş sayısal değerler atanır.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ohe=preprocessing.OneHotEncoder()\n",
    "c=ohe.fit_transform(c).toarray()\n",
    "'''\n",
    "Bu kod parçası, LabelEncoder ile sayısal değerlere dönüştürülmüş olan kategorik verileri, OneHotEncoder kullanarak tekil (one-hot) kodlamaya dönüştürüyor. Adım adım açıklayalım:\n",
    "ohe = preprocessing.OneHotEncoder():\n",
    "\n",
    "    OneHotEncoder sınıfından bir örnek oluşturuyoruz. OneHotEncoder, kategorik verileri ikili (binary) vektörlere dönüştürmek için kullanılır. \n",
    "    Örneğin, 0, 1 ve 2 gibi sayısal kategorileri şu şekilde vektörlere dönüştürür: [1,0,0], [0,1,0] ve [0,0,1].\n",
    "\n",
    "c = ohe.fit_transform(c).toarray():\n",
    "\n",
    "    fit_transform(c): OneHotEncoder'ı veri seti c ile eğitir (fit) ve ardından bu verileri one-hot kodlamalı vektörlere dönüştürür (transform).\n",
    "    toarray(): Bu, elde edilen sparse matrisini (seyrek matris) yoğun (dense) bir NumPy dizisine dönüştürür.\n",
    "    Bu, verilerin kolayca işlenebilmesi ve analiz edilebilmesi için gereklidir.\n",
    "'''\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülke için :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ulke=veriler.iloc[:,0:1].values\n",
    "ulke[:,0]=le.fit_transform(veriler.iloc[:,0])\n",
    "ohe=preprocessing.OneHotEncoder()\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "print(ulke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cinsiyet\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        1.0\n",
      "5        1.0\n",
      "6        1.0\n",
      "7        1.0\n",
      "8        0.0\n",
      "9        1.0\n",
      "10       0.0\n",
      "11       0.0\n",
      "12       0.0\n",
      "13       0.0\n",
      "14       0.0\n",
      "15       1.0\n",
      "16       1.0\n",
      "17       1.0\n",
      "18       1.0\n",
      "19       0.0\n",
      "20       0.0\n",
      "21       0.0\n"
     ]
    }
   ],
   "source": [
    "# Numpy dizileri dataframe donusumu\n",
    "sonuc=pd.DataFrame(data=ulke,index=range(22),columns=['fr','tr','us'])\n",
    "sonuc2=pd.DataFrame(data=Yas,index=range(22),columns=['boy','kilo','yas'])\n",
    "cinsiyet=veriler.iloc[:,-1].values\n",
    "sonuc3=pd.DataFrame(data=c[:,:1],index=range(22),columns=['cinsiyet']) # hem 0 hem 1 kolonunu almamamız lazım o kısım çok önemli\n",
    "print(sonuc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Birleştirme İşlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr   us  boy  kilo  yas  cinsiyet\n",
      "0   0.0  1.0  0.0  130    30   10       1.0\n",
      "1   0.0  1.0  0.0  125    36   11       1.0\n",
      "2   0.0  1.0  0.0  135    34   10       0.0\n",
      "3   0.0  1.0  0.0  133    30    9       0.0\n",
      "4   0.0  1.0  0.0  129    38   12       1.0\n",
      "5   0.0  1.0  0.0  180    90   30       1.0\n",
      "6   0.0  1.0  0.0  190    80   25       1.0\n",
      "7   0.0  1.0  0.0  175    90   35       1.0\n",
      "8   0.0  1.0  0.0  177    60   22       0.0\n",
      "9   0.0  0.0  1.0  185   105   33       1.0\n",
      "10  0.0  0.0  1.0  165    55   27       0.0\n",
      "11  0.0  0.0  1.0  155    50   44       0.0\n",
      "12  0.0  0.0  1.0  160    58   39       0.0\n",
      "13  0.0  0.0  1.0  162    59   41       0.0\n",
      "14  0.0  0.0  1.0  167    62   55       0.0\n",
      "15  1.0  0.0  0.0  174    70   47       1.0\n",
      "16  1.0  0.0  0.0  193    90   23       1.0\n",
      "17  1.0  0.0  0.0  187    80   27       1.0\n",
      "18  1.0  0.0  0.0  183    88   28       1.0\n",
      "19  1.0  0.0  0.0  159    40   29       0.0\n",
      "20  1.0  0.0  0.0  164    66   32       0.0\n",
      "21  1.0  0.0  0.0  166    56   42       0.0\n"
     ]
    }
   ],
   "source": [
    "s=pd.concat([sonuc,sonuc2],axis=1)\n",
    "'''\n",
    "s = pd.concat([sonuc, sonuc2], axis=1):\n",
    "\n",
    "    pd.concat(): pandas kütüphanesindeki concat fonksiyonu, iki veya daha fazla DataFrame'i birleştirmek için kullanılır.\n",
    "    [sonuc, sonuc2]: Bu, birleştirilecek olan iki DataFrame'i içeren bir listedir.\n",
    "    axis=1: Bu parametre, birleştirmenin sütun bazında yapılacağını belirtir. Yani, sonuc ve sonuc2 DataFrame'leri yatay olarak yan yana eklenir.\n",
    "    s: Bu, birleştirilmiş yeni DataFrame'i tutan değişkendir.\n",
    "'''\n",
    "s2=pd.concat([s,sonuc3],axis=1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin Eğitilmesi ve Test İçin Bölünmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :\n",
      "     fr   tr   us  boy  kilo  yas\n",
      "8   0.0  1.0  0.0  177    60   22\n",
      "6   0.0  1.0  0.0  190    80   25\n",
      "16  1.0  0.0  0.0  193    90   23\n",
      "4   0.0  1.0  0.0  129    38   12\n",
      "2   0.0  1.0  0.0  135    34   10\n",
      "5   0.0  1.0  0.0  180    90   30\n",
      "17  1.0  0.0  0.0  187    80   27\n",
      "9   0.0  0.0  1.0  185   105   33\n",
      "7   0.0  1.0  0.0  175    90   35\n",
      "18  1.0  0.0  0.0  183    88   28\n",
      "3   0.0  1.0  0.0  133    30    9\n",
      "0   0.0  1.0  0.0  130    30   10\n",
      "15  1.0  0.0  0.0  174    70   47\n",
      "12  0.0  0.0  1.0  160    58   39\n",
      "x_test :\n",
      "     fr   tr   us  boy  kilo  yas\n",
      "20  1.0  0.0  0.0  164    66   32\n",
      "10  0.0  0.0  1.0  165    55   27\n",
      "14  0.0  0.0  1.0  167    62   55\n",
      "13  0.0  0.0  1.0  162    59   41\n",
      "1   0.0  1.0  0.0  125    36   11\n",
      "21  1.0  0.0  0.0  166    56   42\n",
      "11  0.0  0.0  1.0  155    50   44\n",
      "19  1.0  0.0  0.0  159    40   29\n",
      "y_train :\n",
      "    cinsiyet\n",
      "8        0.0\n",
      "6        1.0\n",
      "16       1.0\n",
      "4        1.0\n",
      "2        0.0\n",
      "5        1.0\n",
      "17       1.0\n",
      "9        1.0\n",
      "7        1.0\n",
      "18       1.0\n",
      "3        0.0\n",
      "0        1.0\n",
      "15       1.0\n",
      "12       0.0\n",
      "y_test :\n",
      "    cinsiyet\n",
      "20       0.0\n",
      "10       0.0\n",
      "14       0.0\n",
      "13       0.0\n",
      "1        1.0\n",
      "21       0.0\n",
      "11       0.0\n",
      "19       0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Bu satır, scikit-learn kütüphanesinden train_test_split fonksiyonunu içe aktarır. Bu fonksiyon, veri setlerini eğitim ve test setlerine ayırmak için kullanılır.\n",
    "x_train,x_test , y_train,y_test=train_test_split(s,sonuc3,test_size=0.33,random_state=0)\n",
    "'''\n",
    "train_test_split(s, sonuc3, test_size=0.33, random_state=0): Bu, s ve sonuc3 veri setlerini eğitim ve test setlerine ayırır.\n",
    "\n",
    "    s: Özellikleri (features) temsil eden DataFrame.\n",
    "    sonuc3: Hedef değişkeni (labels) temsil eden DataFrame.\n",
    "    test_size=0.33: Verilerin %33'ünün test setine, geri kalan %67'sinin eğitim setine ayrılacağını belirtir.\n",
    "    random_state=0: Rastgelelik kontrolü için sabit bir rastgelelik durumunu belirler. Bu, aynı verilerle aynı sonuçları elde etmek için kullanılır.\n",
    "'''\n",
    "print(\"x_train :\")\n",
    "print(x_train)\n",
    "print(\"x_test :\")\n",
    "print(x_test)\n",
    "print(\"y_train :\")\n",
    "print(y_train)\n",
    "print(\"y_test :\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin Ölçeklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntransform(x_test): StandardScaler'ı önceden fit edilen (eğitilen) parametrelerle x_test veri setine uygular. Bu, test verilerini aynı ölçekte standartlaştırır.\\nBu adımda sadece transform kullanılır, çünkü fit_transform kullanmak test verisinin eğitim verisine göre farklı bir ölçeklendirilmesine yol açabilir.\\nEğitim ve test verilerinin aynı ölçekte olması gerekmektedir.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Bu kod parçası, StandardScaler kullanarak eğitim ve test verilerini ölçeklendirir. \n",
    "StandardScaler, verileri standartlaştırarak her özelliğin ortalamasını 0 ve standart sapmasını 1 yapar. \n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Bu satır, scikit-learn kütüphanesinden StandardScaler sınıfını içe aktarır. Bu sınıf, verileri standartlaştırmak için kullanılır.\n",
    "sc=StandardScaler()\n",
    "# StandardScaler sınıfından bir örnek oluşturur. Bu örnek, fit edilip dönüştürülecek veriler için kullanılacaktır.\n",
    "X_train=sc.fit_transform(x_train)\n",
    "'''\n",
    "fit_transform(x_train): StandardScaler'ı x_train veri seti üzerinde fit eder ve ardından bu veri setini dönüştürür. \n",
    "Bu, x_train veri setinin her bir özelliğini standartlaştırır (ortalaması 0, standart sapması 1 olacak şekilde).\n",
    "'''\n",
    "X_test=sc.fit_transform(x_test)\n",
    "'''\n",
    "transform(x_test): StandardScaler'ı önceden fit edilen (eğitilen) parametrelerle x_test veri setine uygular. Bu, test verilerini aynı ölçekte standartlaştırır.\n",
    "Bu adımda sadece transform kullanılır, çünkü fit_transform kullanmak test verisinin eğitim verisine göre farklı bir ölçeklendirilmesine yol açabilir.\n",
    "Eğitim ve test verilerinin aynı ölçekte olması gerekmektedir.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
